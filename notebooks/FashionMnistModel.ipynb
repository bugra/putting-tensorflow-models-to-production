{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3rd Party\n",
    "from baybars.timber import get_logger\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "LABEL_MAP = {\n",
    "  0: 'T-shirt/top',\n",
    "  1: 'Trouser',\n",
    "  2: 'Pullover',\n",
    "  3: 'Dress',\n",
    "  4: 'Coat',\n",
    "  5: 'Sandal',\n",
    "  6: 'Shirt',\n",
    "  7: 'Sneaker',\n",
    "  8: 'Bag',\n",
    "  9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "\n",
    "class UnsupportedModeException(Exception):\n",
    "  pass\n",
    "\n",
    "\n",
    "MODEL_DIR = \"models/fashion_model\"\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "class FashionMNISTCNN(object):\n",
    "\n",
    "  def __init__(self, features, labels, mode, batch_size:int =500, num_epochs:int =100, learning_rate:float =0.01, dropout_rate:float=0.4):\n",
    "    self.features = features \n",
    "    self.labels = labels\n",
    "    self.mode = mode\n",
    "    self.logger = get_logger(str(self.__class__))\n",
    "    self.batch_size = batch_size\n",
    "    self.num_epochs = num_epochs\n",
    "    self.learning_rate = learning_rate\n",
    "    self.dropout_rate = dropout_rate\n",
    "  \n",
    "  def build_network(self):\n",
    "    first_convolution_layer = self.cnn_2d_layer_relu(self.input_layer)\n",
    "    second_convolution_layer = self.cnn_2d_layer_relu(first_convolution_layer)\n",
    "    first_max_pooling_layer = self.max_pool_2d_layer(second_convolution_layer) \n",
    "    third_convolution_layer = self.cnn_2d_layer_relu(first_max_pooling_layer)\n",
    "    fourth_convolution_layer = self.cnn_2d_layer_relu(third_convolution_layer)\n",
    "    second_max_pooling_layer = self.max_pool_2d_layer(fourth_convolution_layer)\n",
    "    reshaped_layer = self.reshape_layer(second_max_pooling_layer)\n",
    "    first_dense_layer = self.dense_layer(reshaped_layer)\n",
    "    first_dropout_layer = self.dropout_layer(first_dense_layer)\n",
    "    second_dense_layer = self.dense_layer(first_dropout_layer)\n",
    "    second_dropout_layer = self.dropout_layer(second_dense_layer)\n",
    "    out_layer = self.logit_layer(second_dropout_layer)\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "  @property\n",
    "  def batch_size(self) -> int:\n",
    "    return self._batch_size\n",
    "\n",
    "  @batch_size.setter\n",
    "  def batch_size(self, value) -> None:\n",
    "    self._batch_size = value\n",
    "  \n",
    "  @property\n",
    "  def num_epochs(self) -> int:\n",
    "    return self._num_epochs\n",
    "\n",
    "  @num_epochs.setter\n",
    "  def num_epochs(self, value) -> None:\n",
    "    self._num_epochs = value\n",
    "\n",
    "  @property\n",
    "  def dropout_rate(self) -> int:\n",
    "    return self._dropout_rate\n",
    "\n",
    "  @dropout_rate.setter\n",
    "  def dropout_rate(self, value) -> None:\n",
    "    self._dropout_rate = value\n",
    "\n",
    "  @property\n",
    "  def is_training(self):\n",
    "    return self.mode == tf.estimator.ModeKeys.TRAIN \n",
    "\n",
    "  @property\n",
    "  def is_evaluate(self):\n",
    "    return self.mode == tf.estimator.ModeKeys.EVAL\n",
    "\n",
    "  @property\n",
    "  def is_predict(self):\n",
    "    return self.mode == tf.estimator.ModeKeys.PREDICT\n",
    "  \n",
    "  @property\n",
    "  def one_hot_labels(self):\n",
    "    return tf.one_hot(indices=tf.cast(self.labels, tf.int32), depth=10)\n",
    "\n",
    "  def loss(self, layer):\n",
    "    return tf.losses.softmax_cross_entropy(onehot_labels=self.one_hot_labels, \n",
    "                                           logits=layer) \n",
    "\n",
    "  @property\n",
    "  def prediction_structure(self, inputs):\n",
    "    return {\n",
    "      \"classes\": tf.argmax(input=inputs, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(inputs, name=\"softmax_tensor\"),\n",
    "    }\n",
    "\n",
    "  def predict(self):\n",
    "    out = None\n",
    "    if self.is_predict:\n",
    "      out_layer = self.build_network()\n",
    "      out = tf.estimator.EstimatorSpec(mode=self.mode, predictions=self.prediction_structure)\n",
    "\n",
    "    return out\n",
    "\n",
    "  def train(self, features=None, labels=None, mode=None):\n",
    "    out = None\n",
    "    if self.is_training:\n",
    "      out_layer = self.build_network()\n",
    "      loss = self.loss(out_layer)\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "      train_op = optimizer.minimize(loss=loss,\n",
    "                                    global_step=tf.train.get_global_step())\n",
    "      tf.summary.scalar('loss', loss)\n",
    "      measure = tf.equal(tf.argmax(out_layer, 1), \n",
    "                         tf.argmax(self.one_hot_labels, 1))\n",
    "      accuracy = tf.reduce_mean(tf.cast(measure, tf.float32))\n",
    "      tf.summary.scalar('accuracy', accuracy)\n",
    "      out = tf.estimator.EstimatorSpec(mode=self.mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def train_model(self, train_data, train_labels, eval_data, eval_labels):\n",
    "    # Might be better to make these into functions to get the training data and labels\n",
    "    train_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "                                                  y=train_labels,\n",
    "                                                  batch_size=self.batch_size,\n",
    "                                                  num_epochs=None,\n",
    "                                                  shuffle=True)\n",
    "\n",
    "    evaluation_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data},\n",
    "                                                       y=eval_labels,\n",
    "                                                       num_epochs=1,\n",
    "                                                       shuffle=False)\n",
    "    for ii in range(self.num_epochs):\n",
    "      self.estimator.train(input_fn=train_fn, steps=100)\n",
    "      eval_results = self.estimator.evaluate(input_fn=evaluation_fn)\n",
    "      predictions = list(self.estimator.predict(input_fn=evaluation_fn))\n",
    "      self.logger.info('epoch={} eval_results={} and predictions={}'.format(ii, eval_results, predictions))\n",
    "\n",
    "    return self.estimator\n",
    "\n",
    "  @property\n",
    "  def estimator(self):\n",
    "    out = None\n",
    "    if self.is_training:\n",
    "      out = tf.estimator.Estimator(model_fn=self.train, model_dir=MODEL_DIR)\n",
    "    elif self.is_evaluate:\n",
    "      out = tf.estimator.Estimator(model_fn=self.evaluate, model_dir=MODEL_DIR)\n",
    "    elif self.is_predict:\n",
    "      out = tf.estimator.Estimator(model_fn=self.predict, model_dir=MODEL_DIR)\n",
    "    else:\n",
    "      raise UnsupportedModeException(\"Mode: {} is not supported for building estimation\".format(self.mode))\n",
    "      \n",
    "    return out\n",
    "  \n",
    "  def evaluate(self, features=None, labels=None, mode=None):\n",
    "    out = None \n",
    "    if self.is_evaluate:\n",
    "      out_layer = self.build_network()\n",
    "      loss = self.loss(out_layer)\n",
    "      evaluation_metric = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=self.labels, \n",
    "                                        predictions=self.prediction_structure[\"classes\"])\n",
    "      }\n",
    "      out = tf.estimator.EstimatorSpec(mode=self.mode, \n",
    "                                       loss=loss, \n",
    "                                       eval_metric_ops=evaluation_metric)\n",
    "\n",
    "    return out\n",
    "\n",
    "  @classmethod\n",
    "  def activation_layer(cls):\n",
    "    return tf.nn.relu\n",
    "\n",
    "  @classmethod\n",
    "  def dense_layer(cls, inputs):\n",
    "    return tf.layers.dense(inputs=inputs, \n",
    "                           units=128, \n",
    "                           activation=cls.activation_layer())\n",
    "\n",
    "  @property\n",
    "  def input_layer(self):\n",
    "    return tf.reshape(self.features, [-1, 28, 28, 1])\n",
    "\n",
    "  @classmethod\n",
    "  def cnn_2d_layer_relu(cls, inputs):\n",
    "    return tf.layers.conv2d(inputs=inputs, \n",
    "                            filters=64, \n",
    "                            kernel_size=[5, 5], \n",
    "                            padding=\"same\", \n",
    "                            activation=cls.activation_layer())\n",
    "  \n",
    "  @classmethod\n",
    "  def max_pool_2d_layer(cls, inputs):\n",
    "    return tf.layers.max_pooling2d(inputs=inputs,\n",
    "                                   pool_size=[2, 2],\n",
    "                                   strides=2)\n",
    "  @classmethod\n",
    "  def reshape_layer(cls, inputs):\n",
    "    return tf.reshape(inputs, [-1, 7 * 7 * 64])\n",
    "\n",
    "  def dropout_layer(self, inputs):\n",
    "    return tf.layers.dropout(inputs=inputs, rate=self.dropout_rate, training=self.is_training)\n",
    "\n",
    "  @classmethod\n",
    "  def logit_layer(cls, inputs):\n",
    "    return tf.layers.dense(inputs=inputs, units=10)\n",
    "\n",
    "  @property\n",
    "  def features(self):\n",
    "    return self._features\n",
    "\n",
    "  @features.setter\n",
    "  def features(self, value):\n",
    "    self._features = value \n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @labels.setter\n",
    "  def labels(self, value):\n",
    "    self._labels = value \n",
    "\n",
    "  @property\n",
    "  def mode(self):\n",
    "    return self._mode\n",
    "\n",
    "  @mode.setter\n",
    "  def mode(self, value):\n",
    "    self._mode = value \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  DATA_DIR = 'data'\n",
    "  from tensorflow.examples.tutorials.mnist import input_data\n",
    "  from sklearn.utils import shuffle\n",
    "  mnist = input_data.read_data_sets(DATA_DIR, one_hot=False, validation_size=0)\n",
    "  train_data = mnist.train.images  \n",
    "  print('train data is loaded')\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  print('train labels is loaded')\n",
    "  train_data, train_labels = shuffle(train_data, train_labels)\n",
    "  print('eval data is loaded')\n",
    "  eval_data = mnist.test.images  \n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "  eval_data, eval_labels = shuffle(eval_data, eval_labels)\n",
    "  fashion_mnist_cnn = FashionMNISTCNN(train_data, train_labels, tf.estimator.ModeKeys.TRAIN)\n",
    "  training = fashion_mnist_cnn.train_model(train_data, train_labels, eval_data, eval_labels)\n",
    "\n",
    "  return fashion_mnist_cnn, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_cnn, training = main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
